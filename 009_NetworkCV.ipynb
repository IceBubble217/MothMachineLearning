{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Callin Switzer\n",
    "### 9 Nov 2018\n",
    "___\n",
    "### - Train Dense, Feedforward Neural Network with Keras\n",
    "### - Use cross validation to find best network hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\calli\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow successfully installed.\n",
      "The installed version of TensorFlow includes GPU support.\n",
      "3.6.4 |Anaconda custom (64-bit)| (default, Jan 16 2018, 10:22:32) [MSC v.1900 64 bit (AMD64)] \n",
      "\n",
      "last run on 2018-11-27 10:34:28.654645\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import seaborn as sns\n",
    "import scipy.io\n",
    "import subprocess\n",
    "import winsound\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import tensorflow as tf\n",
    "print(\"TensorFlow successfully installed.\")\n",
    "if tf.test.is_built_with_cuda():\n",
    "    print(\"The installed version of TensorFlow includes GPU support.\")\n",
    "print(sys.version, \"\\n\")\n",
    "now = datetime.now()\n",
    "print(\"last run on \" + str(now))\n",
    "\n",
    "# define directories\n",
    "baseDir = os.getcwd()\n",
    "dataDir = r'D:\\MothSimulations\\11c-AggressiveManeuver\\Qstore\\hws_am_con'\n",
    "figDir = r'D:\\Dropbox\\AcademiaDropbox\\mothMachineLearning_dataAndFigs\\Figs'\n",
    "dataOutput = r'D:\\Dropbox\\AcademiaDropbox\\mothMachineLearning_dataAndFigs\\DataOutput'\n",
    "savedModels = r'D:\\Dropbox\\AcademiaDropbox\\mothMachineLearning_dataAndFigs\\savedModels'\n",
    "\n",
    "if not os.path.exists(dataOutput):\n",
    "    os.mkdir(dataOutput)\n",
    "if not os.path.exists(savedModels):\n",
    "    os.mkdir(savedModels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>simNum</th>\n",
       "      <th>timestep</th>\n",
       "      <th>F</th>\n",
       "      <th>alpha</th>\n",
       "      <th>phi_0</th>\n",
       "      <th>phi_99</th>\n",
       "      <th>phi_dot_0</th>\n",
       "      <th>phi_dot_99</th>\n",
       "      <th>tau</th>\n",
       "      <th>theta_0</th>\n",
       "      <th>...</th>\n",
       "      <th>x_0</th>\n",
       "      <th>x_99</th>\n",
       "      <th>x_dot_0</th>\n",
       "      <th>x_dot_99</th>\n",
       "      <th>y_0</th>\n",
       "      <th>y_99</th>\n",
       "      <th>y_dot_0</th>\n",
       "      <th>y_dot_99</th>\n",
       "      <th>Fx</th>\n",
       "      <th>Fy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38304.433962</td>\n",
       "      <td>5.340270</td>\n",
       "      <td>3.926991</td>\n",
       "      <td>3.869604</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.674295</td>\n",
       "      <td>10963.268558</td>\n",
       "      <td>0.785398</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.853314</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>683.734561</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.298536</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>-133.752363</td>\n",
       "      <td>22501.211072</td>\n",
       "      <td>-30998.792903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>34264.536249</td>\n",
       "      <td>2.465501</td>\n",
       "      <td>3.948428</td>\n",
       "      <td>4.019544</td>\n",
       "      <td>2.009397</td>\n",
       "      <td>5.425513</td>\n",
       "      <td>72580.767201</td>\n",
       "      <td>0.768478</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019322</td>\n",
       "      <td>-6.079672</td>\n",
       "      <td>-0.145396</td>\n",
       "      <td>-606.129200</td>\n",
       "      <td>2.520087</td>\n",
       "      <td>6.366770</td>\n",
       "      <td>250.908304</td>\n",
       "      <td>120.273149</td>\n",
       "      <td>-26727.166452</td>\n",
       "      <td>21441.012519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>12045.791872</td>\n",
       "      <td>4.573819</td>\n",
       "      <td>3.966608</td>\n",
       "      <td>3.933017</td>\n",
       "      <td>-0.124272</td>\n",
       "      <td>-2.775517</td>\n",
       "      <td>93435.855346</td>\n",
       "      <td>0.768515</td>\n",
       "      <td>...</td>\n",
       "      <td>0.509507</td>\n",
       "      <td>2.986736</td>\n",
       "      <td>52.490438</td>\n",
       "      <td>193.914740</td>\n",
       "      <td>4.834518</td>\n",
       "      <td>2.470847</td>\n",
       "      <td>-18.848146</td>\n",
       "      <td>-211.050011</td>\n",
       "      <td>-1663.845687</td>\n",
       "      <td>-11930.327714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>35562.854879</td>\n",
       "      <td>0.767089</td>\n",
       "      <td>4.000007</td>\n",
       "      <td>4.111777</td>\n",
       "      <td>3.434103</td>\n",
       "      <td>7.246049</td>\n",
       "      <td>-96088.338473</td>\n",
       "      <td>0.773977</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.836633</td>\n",
       "      <td>-4.334782</td>\n",
       "      <td>-187.046694</td>\n",
       "      <td>-157.064454</td>\n",
       "      <td>6.838940</td>\n",
       "      <td>17.508792</td>\n",
       "      <td>218.755312</td>\n",
       "      <td>844.589134</td>\n",
       "      <td>25602.909376</td>\n",
       "      <td>24682.132781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>20856.636628</td>\n",
       "      <td>2.424378</td>\n",
       "      <td>4.009324</td>\n",
       "      <td>3.995061</td>\n",
       "      <td>-2.309667</td>\n",
       "      <td>0.686804</td>\n",
       "      <td>-27142.805375</td>\n",
       "      <td>0.815904</td>\n",
       "      <td>...</td>\n",
       "      <td>0.429770</td>\n",
       "      <td>2.895126</td>\n",
       "      <td>313.730247</td>\n",
       "      <td>-65.350386</td>\n",
       "      <td>8.392823</td>\n",
       "      <td>6.771320</td>\n",
       "      <td>-58.222983</td>\n",
       "      <td>-102.458917</td>\n",
       "      <td>-15718.389244</td>\n",
       "      <td>13708.812166</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   simNum  timestep             F     alpha     phi_0    phi_99  phi_dot_0  \\\n",
       "0       0         0  38304.433962  5.340270  3.926991  3.869604   0.000000   \n",
       "1       0         1  34264.536249  2.465501  3.948428  4.019544   2.009397   \n",
       "2       0         2  12045.791872  4.573819  3.966608  3.933017  -0.124272   \n",
       "3       0         3  35562.854879  0.767089  4.000007  4.111777   3.434103   \n",
       "4       0         4  20856.636628  2.424378  4.009324  3.995061  -2.309667   \n",
       "\n",
       "   phi_dot_99           tau   theta_0      ...            x_0      x_99  \\\n",
       "0   -5.674295  10963.268558  0.785398      ...       0.000000  6.853314   \n",
       "1    5.425513  72580.767201  0.768478      ...      -0.019322 -6.079672   \n",
       "2   -2.775517  93435.855346  0.768515      ...       0.509507  2.986736   \n",
       "3    7.246049 -96088.338473  0.773977      ...      -0.836633 -4.334782   \n",
       "4    0.686804 -27142.805375  0.815904      ...       0.429770  2.895126   \n",
       "\n",
       "      x_dot_0    x_dot_99       y_0       y_99     y_dot_0    y_dot_99  \\\n",
       "0    0.000100  683.734561  0.000000  -1.298536    0.000100 -133.752363   \n",
       "1   -0.145396 -606.129200  2.520087   6.366770  250.908304  120.273149   \n",
       "2   52.490438  193.914740  4.834518   2.470847  -18.848146 -211.050011   \n",
       "3 -187.046694 -157.064454  6.838940  17.508792  218.755312  844.589134   \n",
       "4  313.730247  -65.350386  8.392823   6.771320  -58.222983 -102.458917   \n",
       "\n",
       "             Fx            Fy  \n",
       "0  22501.211072 -30998.792903  \n",
       "1 -26727.166452  21441.012519  \n",
       "2  -1663.845687 -11930.327714  \n",
       "3  25602.909376  24682.132781  \n",
       "4 -15718.389244  13708.812166  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset\n",
    "trainDF2 = pd.read_csv(os.path.join(dataOutput, \"smallDF.csv\"))\n",
    "trainDF2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dataset\n",
    "X = trainDF2.loc[:, [\"x_0\", \"y_0\", \"phi_0\", \"theta_0\", \n",
    "                    \"x_99\", \"y_99\", \"phi_99\", \"theta_99\", \n",
    "                   \"x_dot_0\", \"y_dot_0\", \"phi_dot_0\", \"theta_dot_0\"]]\n",
    "\n",
    "Y = trainDF2.loc[:, [\"Fx\", \"Fy\", \"tau\", \"x_dot_99\", \"y_dot_99\", \n",
    "                    \"phi_dot_99\", \"theta_dot_99\"] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_0</th>\n",
       "      <th>y_0</th>\n",
       "      <th>phi_0</th>\n",
       "      <th>theta_0</th>\n",
       "      <th>x_99</th>\n",
       "      <th>y_99</th>\n",
       "      <th>phi_99</th>\n",
       "      <th>theta_99</th>\n",
       "      <th>x_dot_0</th>\n",
       "      <th>y_dot_0</th>\n",
       "      <th>phi_dot_0</th>\n",
       "      <th>theta_dot_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.926991</td>\n",
       "      <td>0.785398</td>\n",
       "      <td>6.853314</td>\n",
       "      <td>-1.298536</td>\n",
       "      <td>3.869604</td>\n",
       "      <td>0.746382</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.019322</td>\n",
       "      <td>2.520087</td>\n",
       "      <td>3.948428</td>\n",
       "      <td>0.768478</td>\n",
       "      <td>-6.079672</td>\n",
       "      <td>6.366770</td>\n",
       "      <td>4.019544</td>\n",
       "      <td>0.940422</td>\n",
       "      <td>-0.145396</td>\n",
       "      <td>250.908304</td>\n",
       "      <td>2.009397</td>\n",
       "      <td>0.087406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.509507</td>\n",
       "      <td>4.834518</td>\n",
       "      <td>3.966608</td>\n",
       "      <td>0.768515</td>\n",
       "      <td>2.986736</td>\n",
       "      <td>2.470847</td>\n",
       "      <td>3.933017</td>\n",
       "      <td>0.868402</td>\n",
       "      <td>52.490438</td>\n",
       "      <td>-18.848146</td>\n",
       "      <td>-0.124272</td>\n",
       "      <td>-1.029996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.836633</td>\n",
       "      <td>6.838940</td>\n",
       "      <td>4.000007</td>\n",
       "      <td>0.773977</td>\n",
       "      <td>-4.334782</td>\n",
       "      <td>17.508792</td>\n",
       "      <td>4.111777</td>\n",
       "      <td>0.747358</td>\n",
       "      <td>-187.046694</td>\n",
       "      <td>218.755312</td>\n",
       "      <td>3.434103</td>\n",
       "      <td>2.037211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.429770</td>\n",
       "      <td>8.392823</td>\n",
       "      <td>4.009324</td>\n",
       "      <td>0.815904</td>\n",
       "      <td>2.895126</td>\n",
       "      <td>6.771320</td>\n",
       "      <td>3.995061</td>\n",
       "      <td>0.761962</td>\n",
       "      <td>313.730247</td>\n",
       "      <td>-58.222983</td>\n",
       "      <td>-2.309667</td>\n",
       "      <td>-0.673328</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        x_0       y_0     phi_0   theta_0      x_99       y_99    phi_99  \\\n",
       "0  0.000000  0.000000  3.926991  0.785398  6.853314  -1.298536  3.869604   \n",
       "1 -0.019322  2.520087  3.948428  0.768478 -6.079672   6.366770  4.019544   \n",
       "2  0.509507  4.834518  3.966608  0.768515  2.986736   2.470847  3.933017   \n",
       "3 -0.836633  6.838940  4.000007  0.773977 -4.334782  17.508792  4.111777   \n",
       "4  0.429770  8.392823  4.009324  0.815904  2.895126   6.771320  3.995061   \n",
       "\n",
       "   theta_99     x_dot_0     y_dot_0  phi_dot_0  theta_dot_0  \n",
       "0  0.746382    0.000100    0.000100   0.000000     0.000000  \n",
       "1  0.940422   -0.145396  250.908304   2.009397     0.087406  \n",
       "2  0.868402   52.490438  -18.848146  -0.124272    -1.029996  \n",
       "3  0.747358 -187.046694  218.755312   3.434103     2.037211  \n",
       "4  0.761962  313.730247  -58.222983  -2.309667    -0.673328  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fx</th>\n",
       "      <th>Fy</th>\n",
       "      <th>tau</th>\n",
       "      <th>x_dot_99</th>\n",
       "      <th>y_dot_99</th>\n",
       "      <th>phi_dot_99</th>\n",
       "      <th>theta_dot_99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22501.211072</td>\n",
       "      <td>-30998.792903</td>\n",
       "      <td>10963.268558</td>\n",
       "      <td>683.734561</td>\n",
       "      <td>-133.752363</td>\n",
       "      <td>-5.674295</td>\n",
       "      <td>-4.770986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-26727.166452</td>\n",
       "      <td>21441.012519</td>\n",
       "      <td>72580.767201</td>\n",
       "      <td>-606.129200</td>\n",
       "      <td>120.273149</td>\n",
       "      <td>5.425513</td>\n",
       "      <td>10.479995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1663.845687</td>\n",
       "      <td>-11930.327714</td>\n",
       "      <td>93435.855346</td>\n",
       "      <td>193.914740</td>\n",
       "      <td>-211.050011</td>\n",
       "      <td>-2.775517</td>\n",
       "      <td>3.897680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25602.909376</td>\n",
       "      <td>24682.132781</td>\n",
       "      <td>-96088.338473</td>\n",
       "      <td>-157.064454</td>\n",
       "      <td>844.589134</td>\n",
       "      <td>7.246049</td>\n",
       "      <td>0.318982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-15718.389244</td>\n",
       "      <td>13708.812166</td>\n",
       "      <td>-27142.805375</td>\n",
       "      <td>-65.350386</td>\n",
       "      <td>-102.458917</td>\n",
       "      <td>0.686804</td>\n",
       "      <td>-1.304712</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Fx            Fy           tau    x_dot_99    y_dot_99  \\\n",
       "0  22501.211072 -30998.792903  10963.268558  683.734561 -133.752363   \n",
       "1 -26727.166452  21441.012519  72580.767201 -606.129200  120.273149   \n",
       "2  -1663.845687 -11930.327714  93435.855346  193.914740 -211.050011   \n",
       "3  25602.909376  24682.132781 -96088.338473 -157.064454  844.589134   \n",
       "4 -15718.389244  13708.812166 -27142.805375  -65.350386 -102.458917   \n",
       "\n",
       "   phi_dot_99  theta_dot_99  \n",
       "0   -5.674295     -4.770986  \n",
       "1    5.425513     10.479995  \n",
       "2   -2.775517      3.897680  \n",
       "3    7.246049      0.318982  \n",
       "4    0.686804     -1.304712  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test train split\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, test_size=0.2, random_state = 123)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# scale data \n",
    "scalerX = StandardScaler()  \n",
    "scalerY = StandardScaler()  \n",
    "\n",
    "# Don't cheat - fit only on training data\n",
    "scalerX.fit(Xtrain)  \n",
    "scalerY.fit(Ytrain) \n",
    "\n",
    "Xtrain_scaled = scalerX.transform(Xtrain)  \n",
    "Ytrain_scaled = scalerY.transform(Ytrain)  \n",
    "\n",
    "# apply same transformation to test data\n",
    "Xtest_scaled = scalerX.transform(Xtest)\n",
    "Ytest_scaled = scalerY.transform(Ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale data \n",
    "scalerX = MinMaxScaler([-0.5, 0.5])  \n",
    "scalerY = StandardScaler([-0.5, 0.5])  \n",
    "\n",
    "# Don't cheat - fit only on training data\n",
    "scalerX.fit(Xtrain)  \n",
    "scalerY.fit(Ytrain) \n",
    "\n",
    "Xtrain_scaled = scalerX.transform(Xtrain)  \n",
    "Ytrain_scaled = scalerY.transform(Ytrain)  \n",
    "\n",
    "# apply same transformation to test data\n",
    "Xtest_scaled = scalerX.transform(Xtest)\n",
    "Ytest_scaled = scalerY.transform(Ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import\n",
    "from keras.layers import Input, Dense, Dropout, BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "\n",
    "# Keras callcacks\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create network\n",
    "def create_network(optimizer = 'rmsprop', dropout_rate=0.1, \n",
    "                  numUnits = 400, \n",
    "                  NumHiddenLayers = 3, \n",
    "                  weightRegularization = 0.0, \n",
    "                  secondToLastUnits = 16):\n",
    "    K.clear_session()\n",
    "    \n",
    "    inputs = Input(shape=(Xtrain_scaled.shape[1],))\n",
    "    x = Dense(numUnits, activation='tanh')(inputs)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    \n",
    "    for ii in np.arange(1, NumHiddenLayers + 1):\n",
    "        x = Dense(numUnits, activation='tanh', \n",
    "                  kernel_regularizer=regularizers.l1(weightRegularization))(x)\n",
    "        x = Dropout(dropout_rate)(x)\n",
    "    \n",
    "    x = Dense(secondToLastUnits, activation='tanh')(x)\n",
    "    predictions = Dense(Ytrain_scaled.shape[1], activation='linear')(x)\n",
    "\n",
    "    # create model\n",
    "    model = Model(inputs=inputs, outputs=predictions)\n",
    "    model.compile(loss=\"mean_squared_error\", optimizer = optimizer, metrics = ['mse'])\n",
    "\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dict of hyperparameters\n",
    "\n",
    "\n",
    "# regularization, num layers, num nodes, learning rate, optimizer, activation function, batch size\n",
    "\n",
    "from scipy.stats import randint\n",
    "from scipy.stats import uniform\n",
    "\n",
    "# Create hyperparameter space\n",
    "NumHiddenLayers = randint(low = 2, high = 20)#[4, 2, 8]\n",
    "numUnits  = [2**4, 2**5, 2**6, 2**7, 2**8, 2**9, 2**10]\n",
    "epochs = [200]\n",
    "batches1 = [2**12, 2**10, 2**8, 2**14] \n",
    "optimizers = ['rmsprop', 'adam']\n",
    "dropout_rate =  uniform(loc = 0, scale = 0.5) #[0.0, 0.2, 0.5]\n",
    "weightRegularization = uniform(loc = 0, scale = 0.001) #[0, 0.0001, 0.001, 0.01]\n",
    "secondToLastUnits = [8, 16, 32, 64]\n",
    "\n",
    "# Create hyperparameter options\n",
    "hyperparameters = dict(optimizer=optimizers, \n",
    "                        epochs=epochs, \n",
    "                        batch_size=batches1,\n",
    "                        dropout_rate = dropout_rate, \n",
    "                        numUnits = numUnits, \n",
    "                        NumHiddenLayers = NumHiddenLayers, \n",
    "                        weightRegularization = weightRegularization, \n",
    "                        secondToLastUnits = secondToLastUnits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain_scaled_small = Xtrain_scaled[0:8000, :]\n",
    "Ytrain_scaled_small = Ytrain_scaled[0:8000, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystop = EarlyStopping(monitor='val_mean_squared_error', patience=20, \n",
    "                          verbose=1, mode='auto', min_delta = 0.0001)\n",
    "\n",
    "model = KerasRegressor(build_fn=create_network, verbose=0)\n",
    "fit_params = dict(callbacks=[earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stt = time.time()\n",
    "model = KerasRegressor(build_fn=create_network, verbose=0)\n",
    "\n",
    "# Create random search\n",
    "RandomSearch = RandomizedSearchCV(estimator=model, \n",
    "                                    param_distributions=hyperparameters, \n",
    "                                    n_iter = 100, \n",
    "                                    verbose = 1, \n",
    "                                    cv = 2,\n",
    "                                    n_jobs=1, \n",
    "                                    return_train_score= False, \n",
    "                                    scoring = \"neg_mean_squared_error\")\n",
    "\n",
    "# Fit random  search\n",
    "random_result = RandomSearch.fit(Xtrain_scaled, Ytrain_scaled, validation_split = 0.3,\n",
    "                                    **fit_params)\n",
    "endd = time.time() - stt\n",
    "print(endd)\n",
    "\n",
    "# Probably play Windows default sound, if any is registered (because\n",
    "# \"*\" probably isn't the registered name of any sound).\n",
    "# winsound.PlaySound(\"*\", winsound.SND_ALIAS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tstamp = datetime.now().strftime(\"%Y_%m_%d__%H_%M_%S\")\n",
    "\n",
    "with open(os.path.join(dataOutput, \"cvParams_\" + tstamp + \".pkl\"), \"wb\") as fp:   #Pickling\n",
    "    pickle.dump(random_result.cv_results_, fp)\n",
    "    \n",
    "    \n",
    "with open(os.path.join(dataOutput, \"bestParams_\" +  tstamp + \".pkl\"), \"wb\") as fp:   #Pickling\n",
    "    pickle.dump(random_result.best_params_, fp)\n",
    "\n",
    "# with open(\"test.txt\", \"rb\") as fp:   # Unpickling\n",
    "# ...   b = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(os.path.join(dataOutput, \"cvParams_\" + tstamp + \".pkl\"), \"rb\") as fp:   #unPickling\n",
    "#     b = pickle.load(fp)\n",
    "    \n",
    "# print(b)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "random_result.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestParams = random_result.best_params_\n",
    "bestParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_result.best_score_ # negative MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2**12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_network(optimizer = bestParams[\"optimizer\"], \n",
    "                        dropout_rate=bestParams[\"dropout_rate\"], \n",
    "                        numUnits = bestParams[\"numUnits\"], \n",
    "                        NumHiddenLayers = bestParams[\"NumHiddenLayers\"], \n",
    "                        weightRegularization = bestParams[\"weightRegularization\"], \n",
    "                        secondToLastUnits = bestParams['secondToLastUnits'], \n",
    "                        batch_size = bestParams['batch_size'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best model from cv\n",
    "model = create_network(optimizer = \"adam\", \n",
    "                        dropout_rate=0.008, \n",
    "                        numUnits = 16, \n",
    "                        NumHiddenLayers = 5, \n",
    "                        weightRegularization = 0.0007, \n",
    "                        secondToLastUnits = 32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_network(optimizer = \"rmsprop\", \n",
    "                        dropout_rate=0.0, \n",
    "                        numUnits = 16, \n",
    "                        NumHiddenLayers = 5, \n",
    "                        weightRegularization = 0, \n",
    "                        secondToLastUnits = 32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_network(optimizer = \"rmsprop\", \n",
    "                        dropout_rate=0.0, \n",
    "                        numUnits = 128, \n",
    "                        NumHiddenLayers = 5, \n",
    "                        weightRegularization = 0, \n",
    "                        secondToLastUnits = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_network(optimizer = \"rmsprop\", \n",
    "                        dropout_rate=0.0, \n",
    "                        numUnits = 400, \n",
    "                        NumHiddenLayers = 2, \n",
    "                        weightRegularization = 0, \n",
    "                        secondToLastUnits = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                208       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 7)                 231       \n",
      "=================================================================\n",
      "Total params: 2,343\n",
      "Trainable params: 2,343\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.get_config()\n",
    "earlystop = EarlyStopping(monitor='val_mean_squared_error', patience=150, \n",
    "                          verbose=1, mode='auto', min_delta = 0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5600000 samples, validate on 2400000 samples\n",
      "Epoch 1/500\n",
      " - 6s - loss: 0.1930 - mean_squared_error: 0.1930 - val_loss: 0.0457 - val_mean_squared_error: 0.0457\n",
      "Epoch 2/500\n",
      " - 5s - loss: 0.0385 - mean_squared_error: 0.0385 - val_loss: 0.0347 - val_mean_squared_error: 0.0347\n",
      "Epoch 3/500\n",
      " - 5s - loss: 0.0301 - mean_squared_error: 0.0301 - val_loss: 0.0250 - val_mean_squared_error: 0.0250\n",
      "Epoch 4/500\n",
      " - 5s - loss: 0.0247 - mean_squared_error: 0.0247 - val_loss: 0.0201 - val_mean_squared_error: 0.0201\n",
      "Epoch 5/500\n",
      " - 5s - loss: 0.0207 - mean_squared_error: 0.0207 - val_loss: 0.0200 - val_mean_squared_error: 0.0200\n",
      "Epoch 6/500\n",
      " - 5s - loss: 0.0176 - mean_squared_error: 0.0176 - val_loss: 0.0137 - val_mean_squared_error: 0.0137\n",
      "Epoch 7/500\n",
      " - 5s - loss: 0.0149 - mean_squared_error: 0.0149 - val_loss: 0.0154 - val_mean_squared_error: 0.0154\n",
      "Epoch 8/500\n",
      " - 5s - loss: 0.0129 - mean_squared_error: 0.0129 - val_loss: 0.0108 - val_mean_squared_error: 0.0108\n",
      "Epoch 9/500\n",
      " - 5s - loss: 0.0114 - mean_squared_error: 0.0114 - val_loss: 0.0118 - val_mean_squared_error: 0.0118\n",
      "Epoch 10/500\n",
      " - 5s - loss: 0.0103 - mean_squared_error: 0.0103 - val_loss: 0.0085 - val_mean_squared_error: 0.0085\n",
      "Epoch 11/500\n",
      " - 5s - loss: 0.0094 - mean_squared_error: 0.0094 - val_loss: 0.0163 - val_mean_squared_error: 0.0163\n",
      "Epoch 12/500\n",
      " - 5s - loss: 0.0088 - mean_squared_error: 0.0088 - val_loss: 0.0064 - val_mean_squared_error: 0.0064\n",
      "Epoch 13/500\n",
      " - 5s - loss: 0.0083 - mean_squared_error: 0.0083 - val_loss: 0.0076 - val_mean_squared_error: 0.0076\n",
      "Epoch 14/500\n",
      " - 5s - loss: 0.0079 - mean_squared_error: 0.0079 - val_loss: 0.0078 - val_mean_squared_error: 0.0078\n",
      "Epoch 15/500\n",
      " - 5s - loss: 0.0075 - mean_squared_error: 0.0075 - val_loss: 0.0086 - val_mean_squared_error: 0.0086\n",
      "Epoch 16/500\n",
      " - 5s - loss: 0.0073 - mean_squared_error: 0.0073 - val_loss: 0.0052 - val_mean_squared_error: 0.0052\n",
      "Epoch 17/500\n",
      " - 5s - loss: 0.0069 - mean_squared_error: 0.0069 - val_loss: 0.0062 - val_mean_squared_error: 0.0062\n",
      "Epoch 18/500\n",
      " - 6s - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.0061 - val_mean_squared_error: 0.0061\n",
      "Epoch 19/500\n",
      " - 5s - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0086 - val_mean_squared_error: 0.0086\n",
      "Epoch 20/500\n",
      " - 5s - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0069 - val_mean_squared_error: 0.0069\n",
      "Epoch 21/500\n",
      " - 5s - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.0080 - val_mean_squared_error: 0.0080\n",
      "Epoch 22/500\n",
      " - 5s - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.0047 - val_mean_squared_error: 0.0047\n",
      "Epoch 23/500\n",
      " - 5s - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.0053 - val_mean_squared_error: 0.0053\n",
      "Epoch 24/500\n",
      " - 5s - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
      "Epoch 25/500\n",
      " - 5s - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
      "Epoch 26/500\n",
      " - 5s - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.0056 - val_mean_squared_error: 0.0056\n",
      "Epoch 27/500\n",
      " - 5s - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
      "Epoch 28/500\n",
      " - 5s - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
      "Epoch 29/500\n",
      " - 5s - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
      "Epoch 30/500\n",
      " - 5s - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.0071 - val_mean_squared_error: 0.0071\n",
      "Epoch 31/500\n",
      " - 5s - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.0060 - val_mean_squared_error: 0.0060\n",
      "Epoch 32/500\n",
      " - 5s - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0048 - val_mean_squared_error: 0.0048\n",
      "Epoch 33/500\n",
      " - 5s - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0047 - val_mean_squared_error: 0.0047\n",
      "Epoch 34/500\n",
      " - 5s - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
      "Epoch 35/500\n",
      " - 5s - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0047 - val_mean_squared_error: 0.0047\n",
      "Epoch 36/500\n",
      " - 5s - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0049 - val_mean_squared_error: 0.0049\n",
      "Epoch 37/500\n",
      " - 5s - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0052 - val_mean_squared_error: 0.0052\n",
      "Epoch 38/500\n",
      " - 5s - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0054 - val_mean_squared_error: 0.0054\n",
      "Epoch 39/500\n",
      " - 5s - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
      "Epoch 40/500\n",
      " - 5s - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0059 - val_mean_squared_error: 0.0059\n",
      "Epoch 41/500\n",
      " - 6s - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
      "Epoch 42/500\n",
      " - 5s - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0051 - val_mean_squared_error: 0.0051\n",
      "Epoch 43/500\n",
      " - 5s - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
      "Epoch 44/500\n",
      " - 5s - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
      "Epoch 45/500\n",
      " - 5s - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
      "Epoch 46/500\n",
      " - 5s - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
      "Epoch 47/500\n",
      " - 5s - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
      "Epoch 48/500\n",
      " - 5s - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
      "Epoch 49/500\n",
      " - 5s - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0053 - val_mean_squared_error: 0.0053\n",
      "Epoch 50/500\n",
      " - 5s - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0052 - val_mean_squared_error: 0.0052\n",
      "Epoch 51/500\n",
      " - 5s - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
      "Epoch 52/500\n",
      " - 5s - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
      "Epoch 53/500\n",
      " - 5s - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0046 - val_mean_squared_error: 0.0046\n",
      "Epoch 54/500\n",
      " - 5s - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
      "Epoch 55/500\n",
      " - 5s - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
      "Epoch 56/500\n",
      " - 5s - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
      "Epoch 57/500\n",
      " - 5s - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
      "Epoch 58/500\n",
      " - 5s - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
      "Epoch 59/500\n",
      " - 5s - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
      "Epoch 60/500\n",
      " - 5s - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
      "Epoch 61/500\n",
      " - 5s - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
      "Epoch 62/500\n",
      " - 5s - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
      "Epoch 63/500\n",
      " - 5s - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0048 - val_mean_squared_error: 0.0048\n",
      "Epoch 64/500\n",
      " - 5s - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0049 - val_mean_squared_error: 0.0049\n",
      "Epoch 65/500\n",
      " - 5s - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
      "Epoch 66/500\n",
      " - 5s - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
      "Epoch 67/500\n",
      " - 5s - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
      "Epoch 68/500\n",
      " - 5s - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0051 - val_mean_squared_error: 0.0051\n",
      "Epoch 69/500\n",
      " - 5s - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
      "Epoch 70/500\n",
      " - 5s - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
      "Epoch 71/500\n",
      " - 5s - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
      "Epoch 72/500\n",
      " - 5s - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
      "Epoch 73/500\n",
      " - 5s - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
      "Epoch 74/500\n",
      " - 5s - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
      "Epoch 75/500\n",
      " - 5s - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
      "Epoch 76/500\n",
      " - 5s - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
      "Epoch 77/500\n",
      " - 5s - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
      "Epoch 78/500\n",
      " - 5s - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
      "Epoch 79/500\n",
      " - 5s - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
      "Epoch 80/500\n",
      " - 5s - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
      "Epoch 81/500\n",
      " - 5s - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
      "Epoch 82/500\n",
      " - 5s - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0056 - val_mean_squared_error: 0.0056\n",
      "Epoch 83/500\n",
      " - 5s - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
      "Epoch 84/500\n",
      " - 5s - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
      "Epoch 85/500\n",
      " - 5s - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
      "Epoch 86/500\n",
      " - 5s - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
      "Epoch 87/500\n",
      " - 5s - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
      "Epoch 88/500\n",
      " - 5s - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
      "Epoch 89/500\n",
      " - 5s - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
      "Epoch 90/500\n",
      " - 5s - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
      "Epoch 91/500\n",
      " - 5s - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
      "Epoch 92/500\n",
      " - 5s - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
      "Epoch 93/500\n",
      " - 5s - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
      "Epoch 94/500\n",
      " - 5s - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
      "Epoch 95/500\n",
      " - 5s - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0056 - val_mean_squared_error: 0.0056\n",
      "Epoch 96/500\n",
      " - 5s - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
      "Epoch 97/500\n",
      " - 5s - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
      "Epoch 98/500\n",
      " - 5s - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
      "Epoch 99/500\n",
      " - 5s - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
      "Epoch 100/500\n",
      " - 5s - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
      "Epoch 101/500\n",
      " - 5s - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
      "Epoch 102/500\n",
      " - 5s - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
      "Epoch 103/500\n",
      " - 5s - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
      "Epoch 104/500\n",
      " - 5s - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
      "Epoch 105/500\n",
      " - 5s - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
      "Epoch 106/500\n",
      " - 5s - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
      "Epoch 107/500\n",
      " - 5s - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
      "Epoch 108/500\n",
      " - 5s - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0050 - val_mean_squared_error: 0.0050\n",
      "Epoch 109/500\n",
      " - 5s - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
      "Epoch 110/500\n",
      " - 5s - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
      "Epoch 111/500\n",
      " - 5s - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
      "Epoch 112/500\n",
      " - 5s - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
      "Epoch 113/500\n",
      " - 5s - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
      "Epoch 114/500\n",
      " - 5s - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
      "Epoch 115/500\n",
      " - 5s - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
      "Epoch 116/500\n",
      " - 5s - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
      "Epoch 117/500\n",
      " - 5s - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
      "Epoch 118/500\n",
      " - 5s - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
      "Epoch 119/500\n",
      " - 5s - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
      "Epoch 120/500\n",
      " - 5s - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
      "Epoch 121/500\n",
      " - 5s - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
      "Epoch 122/500\n",
      " - 5s - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
      "Epoch 123/500\n",
      " - 5s - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
      "Epoch 124/500\n",
      " - 5s - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
      "Epoch 125/500\n",
      " - 5s - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
      "Epoch 126/500\n",
      " - 5s - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
      "Epoch 127/500\n",
      " - 5s - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
      "Epoch 128/500\n",
      " - 5s - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
      "Epoch 129/500\n",
      " - 5s - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
      "Epoch 130/500\n",
      " - 5s - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
      "Epoch 131/500\n",
      " - 5s - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
      "Epoch 132/500\n",
      " - 5s - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
      "Epoch 133/500\n",
      " - 5s - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
      "Epoch 134/500\n",
      " - 5s - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
      "Epoch 135/500\n",
      " - 5s - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
      "Epoch 136/500\n",
      " - 5s - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
      "Epoch 137/500\n",
      " - 5s - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
      "Epoch 138/500\n",
      " - 5s - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
      "Epoch 139/500\n",
      " - 5s - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
      "Epoch 140/500\n",
      " - 5s - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
      "Epoch 141/500\n",
      " - 5s - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
      "Epoch 142/500\n",
      " - 5s - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
      "Epoch 143/500\n",
      " - 5s - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
      "Epoch 144/500\n",
      " - 5s - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
      "Epoch 145/500\n",
      " - 5s - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
      "Epoch 146/500\n",
      " - 5s - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
      "Epoch 147/500\n",
      " - 5s - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
      "Epoch 148/500\n",
      " - 5s - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
      "Epoch 149/500\n",
      " - 5s - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
      "Epoch 150/500\n",
      " - 5s - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
      "Epoch 151/500\n",
      " - 5s - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
      "Epoch 152/500\n",
      " - 5s - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
      "Epoch 153/500\n",
      " - 5s - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
      "Epoch 154/500\n",
      " - 5s - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
      "Epoch 155/500\n",
      " - 5s - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
      "Epoch 156/500\n",
      " - 5s - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
      "Epoch 157/500\n",
      " - 5s - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
      "Epoch 158/500\n",
      " - 5s - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
      "Epoch 159/500\n",
      " - 5s - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0049 - val_mean_squared_error: 0.0049\n",
      "Epoch 160/500\n",
      " - 5s - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
      "Epoch 161/500\n",
      " - 5s - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
      "Epoch 162/500\n",
      " - 5s - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
      "Epoch 163/500\n",
      " - 5s - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
      "Epoch 164/500\n",
      " - 5s - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
      "Epoch 165/500\n",
      " - 5s - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
      "Epoch 166/500\n",
      " - 5s - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
      "Epoch 167/500\n",
      " - 5s - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
      "Epoch 168/500\n",
      " - 5s - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
      "Epoch 169/500\n",
      " - 5s - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
      "Epoch 170/500\n",
      " - 5s - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
      "Epoch 171/500\n",
      " - 5s - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
      "Epoch 172/500\n",
      " - 5s - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
      "Epoch 173/500\n",
      " - 5s - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n",
      "Epoch 174/500\n",
      " - 5s - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0053 - val_mean_squared_error: 0.0053\n",
      "Epoch 175/500\n",
      " - 5s - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
      "Epoch 176/500\n",
      " - 5s - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
      "Epoch 177/500\n",
      " - 5s - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
      "Epoch 178/500\n",
      " - 5s - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
      "Epoch 179/500\n",
      " - 5s - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
      "Epoch 180/500\n",
      " - 5s - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
      "Epoch 181/500\n",
      " - 5s - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
      "Epoch 182/500\n",
      " - 5s - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
      "Epoch 183/500\n",
      " - 5s - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
      "Epoch 184/500\n",
      " - 5s - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
      "Epoch 185/500\n",
      " - 5s - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
      "Epoch 186/500\n",
      " - 5s - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
      "Epoch 187/500\n",
      " - 5s - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
      "Epoch 188/500\n",
      " - 5s - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
      "Epoch 189/500\n",
      " - 5s - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
      "Epoch 190/500\n",
      " - 5s - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0059 - val_mean_squared_error: 0.0059\n",
      "Epoch 191/500\n",
      " - 5s - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
      "Epoch 192/500\n",
      " - 5s - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
      "Epoch 193/500\n",
      " - 5s - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
      "Epoch 194/500\n",
      " - 5s - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
      "Epoch 195/500\n",
      " - 5s - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
      "Epoch 196/500\n",
      " - 5s - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
      "Epoch 197/500\n",
      " - 5s - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
      "Epoch 198/500\n",
      " - 5s - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
      "Epoch 199/500\n",
      " - 5s - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
      "Epoch 200/500\n",
      " - 5s - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n",
      "Epoch 201/500\n",
      " - 5s - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
      "Epoch 202/500\n",
      " - 5s - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
      "Epoch 203/500\n",
      " - 5s - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
      "Epoch 204/500\n",
      " - 5s - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
      "Epoch 205/500\n",
      " - 5s - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
      "Epoch 206/500\n",
      " - 5s - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
      "Epoch 207/500\n",
      " - 5s - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
      "Epoch 208/500\n",
      " - 5s - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
      "Epoch 209/500\n",
      " - 5s - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
      "Epoch 210/500\n",
      " - 5s - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
      "Epoch 211/500\n",
      " - 5s - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
      "Epoch 212/500\n",
      " - 5s - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
      "Epoch 213/500\n",
      " - 5s - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
      "Epoch 214/500\n",
      " - 5s - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
      "Epoch 215/500\n",
      " - 5s - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
      "Epoch 216/500\n",
      " - 5s - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
      "Epoch 217/500\n",
      " - 5s - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
      "Epoch 218/500\n",
      " - 5s - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
      "Epoch 219/500\n",
      " - 5s - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n",
      "Epoch 220/500\n",
      " - 5s - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
      "Epoch 221/500\n",
      " - 5s - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
      "Epoch 222/500\n",
      " - 5s - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
      "Epoch 223/500\n",
      " - 5s - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
      "Epoch 224/500\n",
      " - 5s - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
      "Epoch 225/500\n",
      " - 5s - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
      "Epoch 226/500\n",
      " - 5s - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
      "Epoch 227/500\n",
      " - 5s - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
      "Epoch 228/500\n",
      " - 5s - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
      "Epoch 229/500\n",
      " - 5s - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n",
      "Epoch 230/500\n",
      " - 5s - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
      "Epoch 231/500\n",
      " - 5s - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
      "Epoch 232/500\n",
      " - 5s - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
      "Epoch 233/500\n",
      " - 5s - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
      "Epoch 234/500\n",
      " - 5s - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
      "Epoch 235/500\n",
      " - 5s - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
      "Epoch 236/500\n",
      " - 5s - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
      "Epoch 237/500\n",
      " - 5s - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
      "Epoch 238/500\n",
      " - 5s - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
      "Epoch 239/500\n",
      " - 5s - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n",
      "Epoch 240/500\n",
      " - 5s - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
      "Epoch 241/500\n",
      " - 5s - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0054 - val_mean_squared_error: 0.0054\n",
      "Epoch 242/500\n",
      " - 5s - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
      "Epoch 243/500\n",
      " - 5s - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
      "Epoch 244/500\n",
      " - 5s - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
      "Epoch 245/500\n",
      " - 5s - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
      "Epoch 246/500\n",
      " - 5s - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
      "Epoch 247/500\n",
      " - 5s - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
      "Epoch 248/500\n",
      " - 5s - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n",
      "Epoch 249/500\n",
      " - 5s - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
      "Epoch 250/500\n",
      " - 5s - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0046 - val_mean_squared_error: 0.0046\n",
      "Epoch 251/500\n",
      " - 5s - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
      "Epoch 252/500\n",
      " - 5s - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
      "Epoch 253/500\n",
      " - 5s - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
      "Epoch 254/500\n",
      " - 5s - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
      "Epoch 255/500\n",
      " - 5s - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
      "Epoch 256/500\n",
      " - 5s - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n",
      "Epoch 257/500\n",
      " - 5s - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
      "Epoch 258/500\n",
      " - 5s - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
      "Epoch 259/500\n",
      " - 5s - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
      "Epoch 260/500\n",
      " - 5s - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
      "Epoch 261/500\n",
      " - 5s - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
      "Epoch 262/500\n",
      " - 5s - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
      "Epoch 263/500\n",
      " - 5s - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
      "Epoch 264/500\n",
      " - 5s - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
      "Epoch 265/500\n",
      " - 5s - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
      "Epoch 266/500\n",
      " - 5s - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
      "Epoch 267/500\n",
      " - 5s - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
      "Epoch 268/500\n",
      " - 5s - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
      "Epoch 269/500\n",
      " - 5s - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
      "Epoch 270/500\n",
      " - 5s - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
      "Epoch 271/500\n",
      " - 5s - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
      "Epoch 272/500\n",
      " - 5s - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
      "Epoch 273/500\n",
      " - 5s - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
      "Epoch 274/500\n",
      " - 5s - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
      "Epoch 275/500\n",
      " - 5s - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n",
      "Epoch 276/500\n",
      " - 5s - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
      "Epoch 277/500\n",
      " - 5s - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
      "Epoch 278/500\n",
      " - 5s - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
      "Epoch 279/500\n",
      " - 5s - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
      "Epoch 280/500\n",
      " - 5s - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0016 - val_mean_squared_error: 0.0016\n",
      "Epoch 281/500\n",
      " - 5s - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
      "Epoch 282/500\n",
      " - 5s - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
      "Epoch 283/500\n",
      " - 5s - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
      "Epoch 284/500\n",
      " - 5s - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
      "Epoch 285/500\n",
      " - 5s - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
      "Epoch 286/500\n",
      " - 5s - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
      "Epoch 287/500\n",
      " - 5s - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
      "Epoch 288/500\n",
      " - 5s - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
      "Epoch 289/500\n",
      " - 5s - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
      "Epoch 290/500\n",
      " - 5s - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
      "Epoch 291/500\n",
      " - 5s - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
      "Epoch 292/500\n",
      " - 5s - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
      "Epoch 293/500\n",
      " - 5s - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
      "Epoch 294/500\n",
      " - 5s - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
      "Epoch 295/500\n",
      " - 5s - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
      "Epoch 296/500\n",
      " - 5s - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
      "Epoch 297/500\n",
      " - 5s - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
      "Epoch 298/500\n",
      " - 5s - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
      "Epoch 299/500\n",
      " - 5s - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
      "Epoch 300/500\n",
      " - 5s - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
      "Epoch 301/500\n",
      " - 5s - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
      "Epoch 302/500\n",
      " - 5s - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
      "Epoch 303/500\n",
      " - 5s - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
      "Epoch 304/500\n",
      " - 5s - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
      "Epoch 305/500\n",
      " - 5s - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n",
      "Epoch 306/500\n",
      " - 5s - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
      "Epoch 307/500\n",
      " - 5s - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
      "Epoch 308/500\n",
      " - 5s - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
      "Epoch 309/500\n",
      " - 5s - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
      "Epoch 310/500\n",
      " - 5s - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
      "Epoch 311/500\n",
      " - 5s - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
      "Epoch 312/500\n",
      " - 5s - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
      "Epoch 313/500\n",
      " - 5s - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
      "Epoch 314/500\n",
      " - 5s - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
      "Epoch 315/500\n",
      " - 5s - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
      "Epoch 316/500\n",
      " - 5s - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
      "Epoch 317/500\n",
      " - 5s - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
      "Epoch 318/500\n",
      " - 5s - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
      "Epoch 319/500\n",
      " - 5s - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
      "Epoch 320/500\n",
      " - 5s - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
      "Epoch 321/500\n",
      " - 5s - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
      "Epoch 322/500\n",
      " - 5s - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
      "Epoch 323/500\n",
      " - 5s - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
      "Epoch 324/500\n",
      " - 5s - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
      "Epoch 325/500\n",
      " - 5s - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
      "Epoch 326/500\n",
      " - 5s - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n",
      "Epoch 327/500\n",
      " - 5s - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
      "Epoch 328/500\n",
      " - 5s - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
      "Epoch 329/500\n",
      " - 5s - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
      "Epoch 330/500\n",
      " - 5s - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
      "Epoch 331/500\n",
      " - 5s - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
      "Epoch 332/500\n",
      " - 5s - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
      "Epoch 333/500\n",
      " - 5s - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n",
      "Epoch 334/500\n",
      " - 5s - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
      "Epoch 335/500\n",
      " - 5s - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n",
      "Epoch 336/500\n",
      " - 5s - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
      "Epoch 337/500\n",
      " - 5s - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
      "Epoch 338/500\n",
      " - 5s - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
      "Epoch 339/500\n",
      " - 5s - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n",
      "Epoch 340/500\n",
      " - 5s - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
      "Epoch 341/500\n",
      " - 5s - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
      "Epoch 342/500\n",
      " - 5s - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
      "Epoch 343/500\n",
      " - 5s - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
      "Epoch 344/500\n",
      " - 5s - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
      "Epoch 345/500\n",
      " - 5s - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
      "Epoch 346/500\n",
      " - 5s - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
      "Epoch 347/500\n",
      " - 6s - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
      "Epoch 348/500\n",
      " - 6s - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
      "Epoch 349/500\n",
      " - 6s - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
      "Epoch 350/500\n",
      " - 5s - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0016 - val_mean_squared_error: 0.0016\n",
      "Epoch 351/500\n",
      " - 5s - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
      "Epoch 352/500\n",
      " - 5s - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
      "Epoch 353/500\n",
      " - 5s - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
      "Epoch 354/500\n",
      " - 5s - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
      "Epoch 355/500\n",
      " - 5s - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
      "Epoch 356/500\n",
      " - 5s - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
      "Epoch 357/500\n",
      " - 5s - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n",
      "Epoch 358/500\n",
      " - 5s - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
      "Epoch 359/500\n",
      " - 5s - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
      "Epoch 360/500\n",
      " - 5s - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n",
      "Epoch 361/500\n",
      " - 5s - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
      "Epoch 362/500\n",
      " - 5s - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
      "Epoch 363/500\n",
      " - 5s - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n",
      "Epoch 364/500\n",
      " - 5s - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
      "Epoch 365/500\n",
      " - 5s - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n",
      "Epoch 366/500\n",
      " - 5s - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
      "Epoch 367/500\n",
      " - 5s - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0017 - val_mean_squared_error: 0.0017\n",
      "Epoch 368/500\n",
      " - 5s - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
      "Epoch 369/500\n",
      " - 5s - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
      "Epoch 370/500\n",
      " - 5s - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
      "Epoch 371/500\n",
      " - 5s - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
      "Epoch 372/500\n",
      " - 5s - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0016 - val_mean_squared_error: 0.0016\n",
      "Epoch 373/500\n",
      " - 5s - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
      "Epoch 374/500\n",
      " - 5s - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0017 - val_mean_squared_error: 0.0017\n",
      "Epoch 375/500\n",
      " - 5s - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
      "Epoch 376/500\n",
      " - 5s - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
      "Epoch 377/500\n",
      " - 5s - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n",
      "Epoch 378/500\n",
      " - 5s - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n",
      "Epoch 379/500\n",
      " - 5s - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
      "Epoch 380/500\n",
      " - 5s - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
      "Epoch 381/500\n",
      " - 5s - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
      "Epoch 382/500\n",
      " - 5s - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
      "Epoch 383/500\n",
      " - 5s - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n",
      "Epoch 384/500\n",
      " - 5s - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
      "Epoch 385/500\n",
      " - 5s - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
      "Epoch 386/500\n",
      " - 5s - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
      "Epoch 387/500\n",
      " - 5s - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
      "Epoch 388/500\n",
      " - 5s - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
      "Epoch 389/500\n",
      " - 5s - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
      "Epoch 390/500\n",
      " - 5s - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n",
      "Epoch 391/500\n",
      " - 5s - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
      "Epoch 392/500\n",
      " - 5s - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
      "Epoch 393/500\n",
      " - 5s - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n",
      "Epoch 394/500\n",
      " - 5s - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0017 - val_mean_squared_error: 0.0017\n",
      "Epoch 395/500\n",
      " - 5s - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
      "Epoch 396/500\n",
      " - 5s - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
      "Epoch 397/500\n",
      " - 5s - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
      "Epoch 398/500\n",
      " - 5s - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
      "Epoch 399/500\n",
      " - 5s - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
      "Epoch 400/500\n",
      " - 5s - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
      "Epoch 401/500\n",
      " - 5s - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
      "Epoch 402/500\n",
      " - 5s - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0017 - val_mean_squared_error: 0.0017\n",
      "Epoch 403/500\n",
      " - 5s - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
      "Epoch 404/500\n",
      " - 5s - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n",
      "Epoch 405/500\n",
      " - 5s - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
      "Epoch 406/500\n",
      " - 5s - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
      "Epoch 407/500\n",
      " - 5s - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
      "Epoch 408/500\n",
      " - 5s - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
      "Epoch 409/500\n",
      " - 5s - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n",
      "Epoch 410/500\n",
      " - 5s - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
      "Epoch 411/500\n",
      " - 5s - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n",
      "Epoch 412/500\n",
      " - 5s - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n",
      "Epoch 413/500\n",
      " - 5s - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0015 - val_mean_squared_error: 0.0015\n",
      "Epoch 414/500\n",
      " - 5s - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
      "Epoch 415/500\n",
      " - 5s - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
      "Epoch 416/500\n",
      " - 5s - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n",
      "Epoch 417/500\n",
      " - 5s - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0016 - val_mean_squared_error: 0.0016\n",
      "Epoch 418/500\n",
      " - 5s - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
      "Epoch 419/500\n",
      " - 5s - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
      "Epoch 420/500\n",
      " - 5s - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
      "Epoch 421/500\n",
      " - 5s - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
      "Epoch 422/500\n",
      " - 5s - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
      "Epoch 423/500\n",
      " - 5s - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0016 - val_mean_squared_error: 0.0016\n",
      "Epoch 424/500\n",
      " - 5s - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
      "Epoch 425/500\n",
      " - 5s - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
      "Epoch 426/500\n",
      " - 5s - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
      "Epoch 427/500\n",
      " - 5s - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
      "Epoch 428/500\n",
      " - 5s - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0016 - val_mean_squared_error: 0.0016\n",
      "Epoch 429/500\n",
      " - 5s - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
      "Epoch 430/500\n",
      " - 5s - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n",
      "Epoch 431/500\n",
      " - 5s - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
      "Epoch 432/500\n",
      " - 5s - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
      "Epoch 433/500\n",
      " - 5s - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
      "Epoch 434/500\n",
      " - 5s - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
      "Epoch 435/500\n",
      " - 5s - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
      "Epoch 436/500\n",
      " - 5s - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
      "Epoch 437/500\n",
      " - 5s - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
      "Epoch 438/500\n",
      " - 5s - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0017 - val_mean_squared_error: 0.0017\n",
      "Epoch 439/500\n",
      " - 5s - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n",
      "Epoch 440/500\n",
      " - 5s - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
      "Epoch 441/500\n",
      " - 5s - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
      "Epoch 442/500\n",
      " - 5s - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
      "Epoch 443/500\n",
      " - 5s - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n",
      "Epoch 444/500\n",
      " - 5s - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n",
      "Epoch 445/500\n",
      " - 5s - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0017 - val_mean_squared_error: 0.0017\n",
      "Epoch 446/500\n",
      " - 5s - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
      "Epoch 447/500\n",
      " - 5s - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
      "Epoch 448/500\n",
      " - 5s - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
      "Epoch 449/500\n",
      " - 5s - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
      "Epoch 450/500\n",
      " - 5s - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n",
      "Epoch 451/500\n",
      " - 5s - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n",
      "Epoch 452/500\n",
      " - 5s - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n",
      "Epoch 453/500\n",
      " - 5s - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
      "Epoch 454/500\n",
      " - 5s - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
      "Epoch 455/500\n",
      " - 5s - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
      "Epoch 456/500\n",
      " - 5s - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
      "Epoch 457/500\n",
      " - 5s - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
      "Epoch 458/500\n",
      " - 5s - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
      "Epoch 459/500\n",
      " - 5s - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
      "Epoch 460/500\n",
      " - 5s - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
      "Epoch 461/500\n",
      " - 5s - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
      "Epoch 462/500\n",
      " - 5s - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
      "Epoch 463/500\n",
      " - 5s - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
      "Epoch 464/500\n",
      " - 5s - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0015 - val_mean_squared_error: 0.0015\n",
      "Epoch 465/500\n",
      " - 5s - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
      "Epoch 466/500\n",
      " - 5s - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
      "Epoch 467/500\n",
      " - 5s - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0017 - val_mean_squared_error: 0.0017\n",
      "Epoch 468/500\n",
      " - 5s - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
      "Epoch 469/500\n",
      " - 5s - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
      "Epoch 470/500\n",
      " - 5s - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
      "Epoch 471/500\n",
      " - 5s - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
      "Epoch 472/500\n",
      " - 5s - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
      "Epoch 473/500\n",
      " - 5s - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
      "Epoch 474/500\n",
      " - 5s - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
      "Epoch 475/500\n",
      " - 5s - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
      "Epoch 476/500\n",
      " - 5s - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
      "Epoch 477/500\n",
      " - 5s - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
      "Epoch 478/500\n",
      " - 5s - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n",
      "Epoch 479/500\n",
      " - 5s - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
      "Epoch 480/500\n",
      " - 5s - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
      "Epoch 481/500\n",
      " - 5s - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
      "Epoch 482/500\n",
      " - 5s - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
      "Epoch 483/500\n",
      " - 5s - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
      "Epoch 484/500\n",
      " - 5s - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
      "Epoch 485/500\n",
      " - 5s - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
      "Epoch 486/500\n",
      " - 5s - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
      "Epoch 487/500\n",
      " - 5s - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
      "Epoch 488/500\n",
      " - 5s - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
      "Epoch 489/500\n",
      " - 5s - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
      "Epoch 490/500\n",
      " - 5s - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
      "Epoch 491/500\n",
      " - 5s - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
      "Epoch 492/500\n",
      " - 5s - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
      "Epoch 493/500\n",
      " - 5s - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
      "Epoch 494/500\n",
      " - 5s - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0015 - val_mean_squared_error: 0.0015\n",
      "Epoch 495/500\n",
      " - 5s - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
      "Epoch 496/500\n",
      " - 5s - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
      "Epoch 497/500\n",
      " - 5s - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0016 - val_mean_squared_error: 0.0016\n",
      "Epoch 498/500\n",
      " - 5s - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
      "Epoch 499/500\n",
      " - 5s - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n",
      "Epoch 500/500\n",
      " - 5s - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
      "2583.489464044571\n"
     ]
    }
   ],
   "source": [
    "\n",
    "stt = time.time()\n",
    "history = model.fit(Xtrain_scaled, Ytrain_scaled, epochs = 500, verbose = 2, \n",
    "                        batch_size =2**14, callbacks = [earlystop], validation_split = 0.3)\n",
    "# Probably play Windows default sound, if any is registered (because\n",
    "# \"*\" probably isn't the registered name of any sound).\n",
    "winsound.PlaySound(\"*\", winsound.SND_ALIAS)\n",
    "endd = time.time() - stt\n",
    "print(endd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0028061076445380848"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history['val_loss'][-1]# MSE for final epoch testing\n",
    "# not sure why it's different from MSE vs. loss????  answer : I think loss incorporates regularization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0028061076445380848"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history['val_mean_squared_error'][-1] # it is the same when there is no regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0024161786221180643"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history['loss'][-1]# MSE for final epoch training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a84a3faa90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_model_history(model_history, saveFig = False):\n",
    "    fig, axs = plt.subplots(1,1,figsize=(10,5))\n",
    "    # summarize history for accuracy\n",
    "    axs.plot(range(1,len(model_history.history['mean_squared_error'])+1),\n",
    "             model_history.history['mean_squared_error'])\n",
    "    axs.plot(range(1,len(model_history.history['val_mean_squared_error'])+1),\n",
    "             model_history.history['val_mean_squared_error'])\n",
    "    axs.set_title('Model MSE')\n",
    "    axs.set_ylabel('mean_squared_error')\n",
    "    axs.set_xlabel('Epoch')\n",
    "    axs.set_xticks(np.arange(1,len(model_history.history['val_mean_squared_error'])+1),\n",
    "                   len(model_history.history['val_mean_squared_error'])/10)\n",
    "    axs.legend(['train', 'val'], loc='best')\n",
    "    if saveFig:\n",
    "        fig.savefig(os.path.join(figDir, \"ModelTraining.png\"), dpi = 120, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "plot_model_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(Xtest_scaled, Ytest_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get nonzero weights\n",
    "wts = model.get_weights().copy()\n",
    "nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "nzwts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trim weights\n",
    "for ii in np.arange(0, 7):\n",
    "    qants = np.percentile(np.reshape(wts[ii], -1), q = (40, 60), )\n",
    "    wts[ii][(wts[ii] > qants[0]) & (wts[ii] < qants[1])] = 0\n",
    "    \n",
    "# calculate number of nonzero weights\n",
    "nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "nzwts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set new weights and calculate new loss\n",
    "model.set_weights(wts)\n",
    "\n",
    "ValLoss = model.evaluate(Xtrain_scaled[-int(0.05*Xtrain_scaled.shape[0]):, :], \n",
    "                         Ytrain_scaled[-int(0.05*Xtrain_scaled.shape[0]):, :])\n",
    "print(ValLoss[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the original model\n",
    "inputs = Input(shape=(Xtrain_scaled.shape[1],))\n",
    "x = Dense(400, activation='tanh')(inputs)\n",
    "x = Dense(400, activation='tanh')(x)\n",
    "x = Dense(400, activation='tanh')(x)\n",
    "x = Dense(16, activation='tanh')(x)\n",
    "predictions = Dense(Ytrain_scaled.shape[1], activation='linear')(x)\n",
    "\n",
    "# create model\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\", metrics = ['mse'])\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_mean_squared_error', patience=50, \n",
    "                          verbose=1, mode='auto', min_delta = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start training\n",
    "history = model.fit(Xtrain_scaled_small, Ytrain_scaled_small, validation_split = 0.3, \n",
    "                    verbose = 2, batch_size=2**14, epochs = 200, \n",
    "                    callbacks = [earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_history(model_history, saveFig = False):\n",
    "    fig, axs = plt.subplots(1,1,figsize=(10,5))\n",
    "    # summarize history for accuracy\n",
    "    axs.plot(range(1,len(model_history.history['mean_squared_error'])+1),\n",
    "             model_history.history['mean_squared_error'])\n",
    "    axs.plot(range(1,len(model_history.history['val_mean_squared_error'])+1),\n",
    "             model_history.history['val_mean_squared_error'])\n",
    "    axs.set_title('Model MSE')\n",
    "    axs.set_ylabel('mean_squared_error')\n",
    "    axs.set_xlabel('Epoch')\n",
    "    axs.set_xticks(np.arange(1,len(model_history.history['val_mean_squared_error'])+1),\n",
    "                   len(model_history.history['val_mean_squared_error'])/10)\n",
    "    axs.legend(['train', 'val'], loc='best')\n",
    "    if saveFig:\n",
    "        fig.savefig(os.path.join(figDir, \"ModelTraining.png\"), dpi = 120, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "plot_model_history(history)\n",
    "print(history.history[\"loss\"][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model that was trained for much longer\n",
    "from keras.models import load_model\n",
    "model = load_model(os.path.join(savedModels, 'my_model.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get nonzero weights\n",
    "wts = model.get_weights().copy()\n",
    "nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "nzwts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set new weights and calculate new loss\n",
    "model.set_weights(wts)\n",
    "\n",
    "ValLoss = model.evaluate(Xtrain_scaled[-int(0.05*Xtrain_scaled.shape[0]):, :], \n",
    "                         Ytrain_scaled[-int(0.05*Xtrain_scaled.shape[0]):, :])\n",
    "print(ValLoss[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show weights histograms\n",
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,5, figsize=np.array((15, 6)) , facecolor='w', edgecolor='k')\n",
    "fig.subplots_adjust(hspace = 0.3, wspace=0.3)\n",
    "axs = axs.ravel(order = \"F\")\n",
    "\n",
    "for ii in range(int(len(wts) / 2)):  \n",
    "    jj= int(2*ii)\n",
    "    axs[jj].hist(wts[jj].reshape(-1), bins = 30)\n",
    "    axs[jj].set_xlabel(\"Layer \" + str(int(jj/2)) + \" weights\" + \", shape = \" + str(wts[jj].shape))\n",
    "    axs[jj+1].hist(wts[jj+1], bins = 30)\n",
    "    axs[jj+1].set_xlabel(\"Layer \" + str(int(jj/2)) + \" biases\" + \", shape = \" + str(wts[jj+1].shape))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on test set\n",
    "nnpreds = model.predict(Xtest_scaled[ :])\n",
    "\n",
    "# rescale\n",
    "nnpreds_unscaled = scalerY.inverse_transform(nnpreds)\n",
    "\n",
    "# show residuals\n",
    "# combine residual and regular plots\n",
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,7, figsize=np.array((30, 8)) / 1.7, facecolor='w', edgecolor='k')\n",
    "fig.subplots_adjust(hspace = 0.1, wspace=0.5)\n",
    "axs = axs.ravel()\n",
    "\n",
    "# replace lightest colors with white\n",
    "import matplotlib.colors\n",
    "cmap = plt.cm.magma_r\n",
    "cmaplist = np.array([cmap(i) for i in range(cmap.N)])\n",
    "cmaplist[:,0:3] = np.divide(cmaplist[:, 0:3], 1.1)\n",
    "cmaplist[0] = (1,1,1,0.5)\n",
    "cmap = matplotlib.colors.LinearSegmentedColormap.from_list('mcm',cmaplist, cmap.N)\n",
    "\n",
    "for ii in range(len(Y.columns)):\n",
    "    \n",
    "    try:\n",
    "        axs[ii].hexbin(y = Ytest.iloc[:,ii],x = nnpreds_unscaled[:,ii], gridsize = 150, cmap = cmap)\n",
    "        axs[ii].yaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n",
    "        axs[ii].ticklabel_format(style='sci',  axis='y', scilimits=(3,4))\n",
    "        axs[ii].axes.xaxis.set_ticklabels([])\n",
    "        if(ii == 0):\n",
    "            axs[ii].set_ylabel(\"Actual Value\")\n",
    "        axs[ii].set_title(nms2[ii])\n",
    "        axs[ii].plot(Ytest.iloc[0:1000,ii], Ytest.iloc[0:1000,ii], 'grey', linewidth = 1, linestyle  = \"--\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "for ii in range(len(Y.columns)):\n",
    "    jj = ii + len(Y.columns)\n",
    "    \n",
    "    try:\n",
    "        axs[jj].hexbin(y = Ytest.iloc[:,ii] - nnpreds_unscaled[:,ii],x = nnpreds_unscaled[:,ii], gridsize = 150, cmap = cmap)\n",
    "        axs[jj].set_xlabel(\"Predicted Value\")\n",
    "        axs[jj].xaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n",
    "        axs[jj].yaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n",
    "        mmin = np.min(Ytest.iloc[:,ii] - nnpreds_unscaled[:,ii])\n",
    "        mmax = np.max(Ytest.iloc[:,ii] - nnpreds_unscaled[:,ii])\n",
    "        \n",
    "        upper = np.max([np.abs(mmin), np.abs(mmax)])\n",
    "        axs[jj].set_ylim(-upper, upper)\n",
    "\n",
    "        if(ii == 0):\n",
    "            axs[jj].set_ylabel(\"Actual - Predicted\")\n",
    "        axs[jj].hlines(y = 0, xmin = np.min(nnpreds_unscaled[:,ii]), \n",
    "                       xmax = np.max(nnpreds_unscaled[:,ii]), linestyle =  \"--\", linewidth = 1)\n",
    "    except:\n",
    "        pass\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trim distribution of weights -- cut out middle 20%\n",
    "for ii in np.arange(0, 7):\n",
    "    qants = np.percentile(np.reshape(wts[ii], -1), q = (40, 60), )\n",
    "    wts[ii][(wts[ii] > qants[0]) & (wts[ii] < qants[1])] = 0\n",
    "    \n",
    "# calculate number of nonzero weights\n",
    "nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "nzwts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show new histogram of weights (excluding the 0's)\n",
    "# show weights histograms\n",
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,5, figsize=np.array((15, 6)) , facecolor='w', edgecolor='k')\n",
    "fig.subplots_adjust(hspace = 0.3, wspace=0.3)\n",
    "axs = axs.ravel(order = \"F\")\n",
    "\n",
    "for ii in range(int(len(wts) / 2)):  \n",
    "    jj= int(2*ii)\n",
    "    \n",
    "    d1 = wts[jj].reshape(-1)\n",
    "    axs[jj].hist(d1[d1!=0], bins = 30, facecolor = '#d6bddb' )\n",
    "    axs[jj].set_xlabel(\"Layer \" + str(int(jj/2)) + \" weights\" + \", shape = \" + str(wts[jj].shape))\n",
    "\n",
    "    d2 = wts[jj+1]\n",
    "    axs[jj+1].hist(d2[d2!=0], bins = 30, facecolor = '#d6bddb')\n",
    "    axs[jj+1].set_xlabel(\"Layer \" + str(int(jj/2)) + \" biases\" + \", shape = \" + str(wts[jj+1].shape))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the validation.split is the last X% of the data\n",
    "int(0.3*Xtrain_scaled.shape[0])\n",
    "ValLoss = model.evaluate(Xtrain_scaled[-int(0.3*Xtrain_scaled.shape[0]):, :], \n",
    "                         Ytrain_scaled[-int(0.3*Xtrain_scaled.shape[0]):, :])\n",
    "print(ValLoss[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set new weights and calculate new loss\n",
    "model.set_weights(wts)\n",
    "\n",
    "ValLoss = model.evaluate(Xtrain_scaled[-int(0.3*Xtrain_scaled.shape[0]):, :], \n",
    "                         Ytrain_scaled[-int(0.3*Xtrain_scaled.shape[0]):, :])\n",
    "print(ValLoss[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on test set\n",
    "nnpreds = model.predict(Xtest_scaled[ :])\n",
    "\n",
    "# rescale\n",
    "nnpreds_unscaled = scalerY.inverse_transform(nnpreds)\n",
    "\n",
    "# show residuals\n",
    "# combine residual and regular plots\n",
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,7, figsize=np.array((30, 8)) / 1.7, facecolor='w', edgecolor='k')\n",
    "fig.subplots_adjust(hspace = 0.1, wspace=0.5)\n",
    "axs = axs.ravel()\n",
    "\n",
    "# replace lightest colors with white\n",
    "import matplotlib.colors\n",
    "cmap = plt.cm.magma_r\n",
    "cmaplist = np.array([cmap(i) for i in range(cmap.N)])\n",
    "cmaplist[:,0:3] = np.divide(cmaplist[:, 0:3], 1.1)\n",
    "cmaplist[0] = (1,1,1,0.5)\n",
    "cmap = matplotlib.colors.LinearSegmentedColormap.from_list('mcm',cmaplist, cmap.N)\n",
    "\n",
    "for ii in range(len(Y.columns)):\n",
    "    \n",
    "    try:\n",
    "        axs[ii].hexbin(y = Ytest.iloc[:,ii],x = nnpreds_unscaled[:,ii], gridsize = 150, cmap = cmap)\n",
    "        axs[ii].yaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n",
    "        axs[ii].ticklabel_format(style='sci',  axis='y', scilimits=(3,4))\n",
    "        axs[ii].axes.xaxis.set_ticklabels([])\n",
    "        if(ii == 0):\n",
    "            axs[ii].set_ylabel(\"Actual Value\")\n",
    "        axs[ii].set_title(nms2[ii])\n",
    "        axs[ii].plot(Ytest.iloc[0:1000,ii], Ytest.iloc[0:1000,ii], 'grey', linewidth = 1, linestyle  = \"--\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "for ii in range(len(Y.columns)):\n",
    "    jj = ii + len(Y.columns)\n",
    "    \n",
    "    try:\n",
    "        axs[jj].hexbin(y = Ytest.iloc[:,ii] - nnpreds_unscaled[:,ii],x = nnpreds_unscaled[:,ii], gridsize = 150, cmap = cmap)\n",
    "        axs[jj].set_xlabel(\"Predicted Value\")\n",
    "        axs[jj].xaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n",
    "        axs[jj].yaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n",
    "        mmin = np.min(Ytest.iloc[:,ii] - nnpreds_unscaled[:,ii])\n",
    "        mmax = np.max(Ytest.iloc[:,ii] - nnpreds_unscaled[:,ii])\n",
    "        \n",
    "        upper = np.max([np.abs(mmin), np.abs(mmax)])\n",
    "        axs[jj].set_ylim(-upper, upper)\n",
    "\n",
    "        if(ii == 0):\n",
    "            axs[jj].set_ylabel(\"Actual - Predicted\")\n",
    "        axs[jj].hlines(y = 0, xmin = np.min(nnpreds_unscaled[:,ii]), \n",
    "                       xmax = np.max(nnpreds_unscaled[:,ii]), linestyle =  \"--\", linewidth = 1)\n",
    "    except:\n",
    "        pass\n",
    "plt.tight_layout()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
